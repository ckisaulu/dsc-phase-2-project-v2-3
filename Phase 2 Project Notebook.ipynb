{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 Project Submission: Group 12\n",
    "\n",
    "**Student names:**\n",
    "\n",
    "1. George Tido\n",
    "2. Caroline Kisaulu \n",
    "3. Caroline Ngabu \n",
    "4. Vivian Maiyo \n",
    "5. Faith Gitau \n",
    "6. Lewis Gitari\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Price Prediction in King County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The real estate industry is intricate, with numerous factors influencing property prices. Accurate house price predictions benefit both sellers and buyers. In this project, we will utilize the King County House data, which provides information on real estate prices in King County, Washington. The goal is to construct a regression model that predicts house selling prices based on various features. Regression analysis techniques will be employed to analyze the data and develop a model capable of estimating house prices. This project aims to offer insights into the factors influencing house prices, aiding informed decision-making for both buyers and sellers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "The surge in population has led to a lack of affordable housing, intensifying demand.\n",
    "Misrepresentation of house grade by property owners or developers, potentially driving prices up.\n",
    "Limited availability of residential units in King County, causing increased costs across different grades.\n",
    "Disparities in the housing market, especially in desirable areas, leading to high property values.\n",
    "Limited land supply, particularly in sought-after locations close to job centers and transportation.\n",
    "\n",
    "**Proposed Solutions:**\n",
    "\n",
    "Increase affordable housing by identifying essential house features that don't inflate prices.\n",
    "Implement stringent, independent standards for house grading, detaching from developers' influence.\n",
    "Construct high-rise buildings to counteract land scarcity in desirable areas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "To develop a linear regression model capable of accurately predicting house prices in King County.\n",
    "\n",
    "To analyze the relationship between home features and house sale prices in King County. \n",
    "\n",
    "To provide data driven insights to real estate stakeholders on maximizing returns by focusing on features with the most significant impact on house sale prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Questions\n",
    "\n",
    "1. Which predictor variables are correlated with the dependent variable (house sale price)?\n",
    "2. Which variables best predict the house sale price in a multiple linear regression model?\n",
    "3. Which house features can developers focus on to enhance affordable housing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### King County Dataset Column Names and Descriptions\n",
    "\n",
    "- **id** - Unique identifier for a house\n",
    "- **date** - Date house was sold\n",
    "- **price** - Sale price (prediction target)\n",
    "- **bedrooms** - Number of bedrooms\n",
    "- **bathrooms** - Number of bathrooms\n",
    "- **sqft_living** - Square footage of living space in the home\n",
    "- **sqft_lot** - Square footage of the lot\n",
    "- **floors** - Number of floors (levels) in house\n",
    "- **waterfront** - Whether the house is on a waterfront\n",
    "- **view** - Quality of view from house\n",
    "- **condition** - How good the overall condition of the house is. Related to maintenance of house.\n",
    "- **grade** - Overall grade of the house. Related to the construction and design of the house.\n",
    "- **sqft_above** - Square footage of house apart from basement\n",
    "- **sqft_basement** - Square footage of the basement\n",
    "- **yr_built** - Year when house was built\n",
    "- **yr_renovated** - Year when house was renovated\n",
    "- **zipcode** - ZIP Code used by the United States Postal Service\n",
    "- **lat** - Latitude coordinate\n",
    "- **long** - Longitude coordinate\n",
    "- **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "- **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sfm\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "\n",
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation\n",
    "#Summary of the Data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of unique values\n",
    "\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the total number of null values\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the percentage of Missing values\n",
    "\n",
    "def miss_percent(df, col):\n",
    "    miss = ((df[col].sum()) / len(df[col])) * 100\n",
    "    return print(f'There is {miss} percent of values missing in {col}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentage of missing values in waterfront\n",
    "\n",
    "dfmiss = (df.isna().sum()/len(df))*100\n",
    "dfmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with yr_renovated\n",
    "\n",
    "df['yr_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the null with a specified value\n",
    "\n",
    "def replace_nan(df,col, replace_value):\n",
    "    return df[col].fillna(replace_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the null values\n",
    "df['yr_renovated'].replace(0.0, np.nan, inplace=True)\n",
    "df['yr_renovated'].fillna(df['yr_built'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming the null values have been removed\n",
    "miss_percent(df, 'yr_renovated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with Waterfront missing values\n",
    "#Investigating the columns\n",
    "\n",
    "print(f'Unique values: {df.waterfront.unique()}')\n",
    "print(f'Count: {df.waterfront.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the null values with zero\n",
    "\n",
    "replace_nan(df, 'waterfront', 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing a value with another\n",
    "def substitute(df,col,original_value, sub_value):\n",
    "    return df[col].replace(original_value, sub_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing YES to 1\n",
    "\n",
    "substitute(df, 'waterfront', 'YES',1)\n",
    "\n",
    "# changing NO to 0\n",
    "substitute(df, 'waterfront', 'NO', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  confirming null values are out\n",
    "\n",
    "miss_percent(df, 'waterfront')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with VIEW\n",
    "#Investigating the Colum\n",
    "\n",
    "print(f'Unique values:{df.view.unique()}')\n",
    "print(f'Count:{df.view.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Null values with Nun\n",
    "\n",
    "replace_nan(df,'view', 'NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the rating to numbers\n",
    "\n",
    "substitute(df, 'view', ['NONE', 'FAIR', 'AVERAGE', 'GOOD','EXCELLENT'],[0,1 ,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking count\n",
    "\n",
    "df['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with sqft_basement\n",
    "# investigating the column\n",
    "\n",
    "print(f'Count:{df.sqft_basement.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column has ? as an entry. 0.0 is the most occuring and we change ? to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ? to 0.0\n",
    "\n",
    "substitute(df, 'sqft_basement', '?', 0.0)\n",
    "df.sqft_basement = df.sqft_basement.astype(float)\n",
    "print(f'Count:{df.sqft_basement.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with condition\n",
    "#investigating the column\n",
    "\n",
    "print(f'Unique value:{df.condition.unique()}')\n",
    "print(f'Count:{df.condition.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 ratings and we decide to assign them numbers on a scale of 1 to 5 with 5 being very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the ratings numbers\n",
    "\n",
    "substitute(df, 'condition', ['Poor', 'Fair', 'Average', 'Good', 'Very Good'],[1,2,3,4,5])\n",
    "print(f'Unique values:{df.condition.unique()}')\n",
    "print(f'Count:{df.condition.value_counts()}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with Grade\n",
    "#Investigating the colum\n",
    "\n",
    "print(f'Unique values:{df.grade.unique()}')\n",
    "print(f'Count:{df.grade.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the ratings as numbers with the numbers they have beside them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute(df, 'grade', ['3 Poor', '4 Low', '5 Fair', '6 Low Average', '7 Average', '8 Good', '9 Better', '10 Very Good', '11 Excellent', '12 Luxury', '13 Mansion'],[3,4,5,6,7,8,9,10,11,12,13])\n",
    "print(f'Unique values:{df.grade.unique()}')\n",
    "print(f'Count:{df.grade.value_counts()}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with Bathrooms\n",
    "#Investigating the colum\n",
    "\n",
    "print(f'Count:{df.bathrooms.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bathrooms have float values. We decided to round up to the next integer so as to have whole numbers. In this case, rounding off might make the 0.5 to be 0 which we don't want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding up the decimals\n",
    "df['bathrooms'] = df['bathrooms'].apply(np.ceil).astype(int)\n",
    "df.bathrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if we have duplicates on our dataset\n",
    "\n",
    "duplicates = []\n",
    "def identify_duplicates(data):\n",
    "    for i in data.duplicated():\n",
    "        duplicates.append(i)\n",
    "    duplicates_set = set(duplicates)\n",
    "    if(len(duplicates_set) == 1):\n",
    "        print('The data has no duplicates')\n",
    "    else:\n",
    "        duplicates_rows = 0\n",
    "        for j in duplicates:\n",
    "            if (j == True):\n",
    "                duplicates_rows += 1\n",
    "                # percentage of data represented by duplicates\n",
    "                duplicates_percentage = np.round(((duplicates_rows/len(data)) * 100), 2)\n",
    "                print(f'The data has {duplicates_rows} duplicated rows')\n",
    "                print(f'Duplicated rows contitute of {duplicates_percentage}% of the dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for outliers using histograms to help us get insights of the spread of various features\n",
    "\n",
    "df.hist(figsize = (15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* grade, condition and floors appear to be on a reasonable scale with no apparent outliers.\n",
    "\n",
    "* Waterfront is a binary 1/10 features.\n",
    "\n",
    "* I need to consider potential outliers in bedrooms, bathrooms and the sqft-type features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating  bedrooms\n",
    "\n",
    "df['bedrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on bedrooms with 33\n",
    "\n",
    "df[df['bedrooms'] == 33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The house has 2 bathrooms and a price of 640,000. This seem to indicate 33 might have been an error. Replace it with 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing error for bedrooms\n",
    "\n",
    "def remove_outliers(df):\n",
    "    # define the columns to remove outliers from\n",
    "    cols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15']\n",
    "\n",
    "    # remove outliers from the specified columns\n",
    "    for col in cols:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        df = df[(df[col] >= q1 - (2.5 * iqr * (len(df[col]) / (len(df[col]) + 1)))) & (df[col] <= q3 + (2.5 * iqr * (len(df[col]) / (len(df[col]) + + 1))))]\n",
    "    \n",
    "    # return the modified DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing price distribution\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "dist=sns.distplot(df[\"price\"])\n",
    "dist.set_title(\"Price distribution\")\n",
    "plt.xlabel('Price in USD')\n",
    "plt.title('Distribution of Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing Price Distribution\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "sns.distplot(np.log(df['price']), bins = 100) \n",
    "\n",
    "ax.set_xlabel(\"Normalized Price\")\n",
    "ax.set_ylabel(\"Number of houses\")\n",
    "ax.set_title(\"Normalized house prices distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring how waterfront features influences the prices of a house\n",
    "#Distribution of a Water front feture\n",
    "\n",
    "sns.displot(data=df, x='waterfront')\n",
    "plt.title('Distribution of waterfront')\n",
    "plt.xlabel('Waterfront')\n",
    "plt.ylabel('Properties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the properties do not have a waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot of waterfront feature\n",
    "\n",
    "sns.boxplot(x = df['waterfront'], y = df['price'])\n",
    "plt.title(\"Boxplot of waterfront feature vs. price\")\n",
    "plt.ylabel(\"price in USD\")\n",
    "plt.xlabel(None)\n",
    "plt.xticks(np.arange(2), ('No view of waterfront', 'Waterfront view'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfrontmean = df[df['waterfront'] == 1]['price'].mean()\n",
    "nowaterfrontmean = df[df['waterfront'] == 0]['price'].mean()\n",
    "print(f\"The mean  price for a house with waterfront  is  {round(waterfrontmean,2)} USD\")\n",
    "print(f\"The mean  price for a house without waterfront is  {round(nowaterfrontmean,2)} USD\")\n",
    "print(f\"Percentage of houses with waterfront is: {len(df[df['waterfront'] == 1])/len(df)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above findings we can conclude;\n",
    "\n",
    "Waterfront has a significant effect on the price with the mean price of houses with waterfront being almost double of those without. However only about 0.20% of houses have a waterfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features that can be considered to be 'attached' to the house.\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables\n",
    "features = ['bedrooms', 'bathrooms', 'floors', 'view', 'grade', 'condition']\n",
    "\n",
    "# plot boxplots\n",
    "for feature in features:\n",
    "    sns.boxplot(x = df[feature], y = df['price'])\n",
    "    plt.title(f\"Boxplot of {feature} vs. price\")\n",
    "    plt.ylabel(\"price in USD\")\n",
    "    plt.xlabel(f\"{feature}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can conclude the following;\n",
    "\n",
    "As bedrooms increase so does the price. 5 bedrooms seem to be the most preferred.\n",
    "\n",
    "As the bathrooms increase the price increases.\n",
    "\n",
    "Floors also seem to affect the price and 2.5 seems to be the most common.\n",
    "\n",
    "The view also increases the price with 4: Excellent being the most expensive.\n",
    "\n",
    "The grade is also affecting the price increase. The higer the grade, the higher the sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation for Modelling\n",
    "#Investigating for linearity assumption\n",
    "#investigating the relationship between price and the continuous variables in our data\n",
    "\n",
    "features = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "\n",
    "#  Plot jointplots\n",
    "for feature in features:\n",
    "    sns.jointplot(x = df[feature], y = df['price'], kind = 'reg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features appear to be linear. sqft_living and sqft_above show the best linearity with respect to price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigating Multi collinearity using correllation heatmap\n",
    "\n",
    "cor_df = df.drop(['yr_renovated','zipcode','lat','long'], axis=1)\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "mask = np.triu(np.ones_like(cor_df.corr()))\n",
    "sns.heatmap(cor_df.corr(), cmap=\"coolwarm\", annot=True, mask=mask)\n",
    "plt.title('Correlation of the features')\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity problems need to be addressed. \n",
    "The following predictor variable pairs have a high correlation which can cause multicollinearity problems:\n",
    "1. sqft_above and sqft_living - 0.85\n",
    "2. sqft_living and sqft_living15 - 0.74\n",
    "3. sqft_lot and sqft_lot15 - 0.71\n",
    "4. sqft_above and grade\n",
    "\n",
    "To retain more information, we will retain sqft_living as it has a higher correlation with price and proceed to eliminate sqft_above and sqft_living15. \n",
    "Similarly, there is a substantial correlation between sqft_lot and sqft_lot15. We will opt to keep sqft_lot, as it directly pertains to the property itself.\n",
    "We will also retain grade because of the wealth of information it encompasses as it comprises several features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the features with multicollinearity problems\n",
    "\n",
    "df = df.drop(['sqft_above', 'sqft_living15', 'sqft_lot15'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have removed the variables with multicollinearity, we need to select the features to use in our model based on the strength of their correlation with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = cor_df.corr()\n",
    "features = []\n",
    "correlations = []\n",
    "for idx, correlation in corr['price'].T.iteritems():\n",
    "    features.append(idx)\n",
    "    correlations.append(correlation)\n",
    "corr_price_df = pd.DataFrame({'Correlations':correlations, 'Feature': features}).sort_values(by=['Correlations'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlations with Price')\n",
    "display(corr_price_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting features to use in regression modeling\n",
    "1. Grade - has a higher correlation with price than overall condition \n",
    "2. sqft_living \n",
    "3. bathrooms\n",
    "4. bedrooms\n",
    "5. floors\n",
    "6. sqft_lot\n",
    "7. yr_built\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictors\n",
    "\n",
    "predictors = df['sqft_living']\n",
    "\n",
    "# creating model intercept\n",
    "\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "\n",
    "# fitting baseline model\n",
    "\n",
    "baseline_model = sm.OLS(df['price'], predictors_int).fit()\n",
    "\n",
    "# checking model\n",
    "\n",
    "print(baseline_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check normality assumption\n",
    "\n",
    "residuals = baseline_model.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to highlight that two out of three assumptions of linearity are not met in this context. Specifically, the residuals do not exhibit a normal distribution, and the data lacks homoscedasticity. Our approach involves generating a summary of the current model, exploring the potential benefits of applying log transformations to both price and sqft_living to address these issues, and evaluating whether the inclusion of additional variables in our model can enhance the R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying logarithmic function to independant variable\n",
    "df['log_sqft_living'] = np.log(df['sqft_living'])\n",
    "\n",
    "\n",
    "# re-creating the model with `log_sqft_living`\n",
    "# creating predictors\n",
    "\n",
    "predictors = df['log_sqft_living']\n",
    "\n",
    "# creating model intercept\n",
    "\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "\n",
    "# fit model\n",
    "\n",
    "log_model1 = sm.OLS(df['price'], predictors_int).fit()\n",
    "\n",
    "# checking model\n",
    "\n",
    "print(log_model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = log_model1.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying logarithmic function to dependant variable\n",
    "\n",
    "df['log_price'] = np.log(df['price'])\n",
    "\n",
    "\n",
    "# re-creating the model with `sqft_living`\n",
    "# creating predictors\n",
    "\n",
    "predictors = df['sqft_living']\n",
    "\n",
    "# creating model intercept\n",
    "\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "\n",
    "# fit model\n",
    "log_model2 = sm.OLS(df['log_price'], predictors_int).fit()\n",
    "\n",
    "# checking model\n",
    "\n",
    "print(log_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = log_model2.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING BEDROOMS\n",
    "# creating predictors\n",
    "\n",
    "predictors = df[['sqft_living', 'bedrooms']]\n",
    "\n",
    "# creating model intercept\n",
    "\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "\n",
    "# fitting model\n",
    "\n",
    "second_model = sm.OLS(df['log_price'], predictors_int).fit()\n",
    "\n",
    "# checking model\n",
    "\n",
    "print(second_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking normality assumption\n",
    "\n",
    "residuals = second_model.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADE\n",
    "\n",
    "# Creating a simple linear model using grade\n",
    "\n",
    "y = df[\"price\"]\n",
    "x = df[[\"grade\"]]\n",
    "model_grade = sm.OLS(endog=y, exog=sm.add_constant(x))\n",
    "grade_results = model_grade.fit()\n",
    "print(grade_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking normality assumption\n",
    "\n",
    "residuals = grade_results.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "\n",
    "x = df[['sqft_living', 'bedrooms', 'yr_built', 'grade']]\n",
    "y = df['price']\n",
    "predictors_int = sm.add_constant(x)\n",
    "\n",
    "# fitting model\n",
    "\n",
    "multilinear = sm.OLS(df['price'], predictors_int).fit()\n",
    "\n",
    "# checking model\n",
    "\n",
    "print(multilinear.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking Normality assumption\n",
    "\n",
    "residuals = multilinear.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Multiple Linear Regression Model 2 with all the chosen variables\n",
    "\n",
    "x = df[['sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms', 'grade', 'yr_built']]\n",
    "y = df['price']\n",
    "predictors_int = sm.add_constant(x)\n",
    "\n",
    "# fitting model\n",
    "\n",
    "multilinear_2 = sm.OLS(df['price'], predictors_int)\n",
    "results = multilinear_2.fit()\n",
    "\n",
    "# checking model\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residuals = results.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "plt.title(\"Normality check\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best R-squared value was from the above model comprising six of the regression variables namely: sqft_living, sqft_lot, bedrooms, bathrooms, grade, and yr_built.\n",
    "\n",
    "The R-squared value is stands at 0.582, indicating that 58.2% of the price variation can be elucidated by the independent variables within the model.\n",
    "\n",
    "The F-statistic of 4404 has a p-value of 0.00 meaning that the model is statistically significant at a set alpha value of 0.05 since 0.00 is below 0.05\n",
    "\n",
    "The co-efficient of the constant is also statistically significant with a p-value of 0.00\n",
    "\n",
    "For individual variables:\n",
    "\n",
    "- All the p-values of the coefficients are statistically significant as they are all 0.00\n",
    "\n",
    "- **sqft_living:** The coefficient of 127.7869 signifies that a one-unit increase in square footage correlates with a $121.78 rise in price, with all other variables held constant.\n",
    "\n",
    "- **sqft_lot**: The coefficient of -5.8597 signifies that a one-unit increase in square footage of the lot correlates with a $5.85 decrease in price, with all other variables held constant.\n",
    "\n",
    "- **bedrooms:** With a coefficient of -2.228e+04, the presence of an additional bedroom is linked to a $222800 decrease in price, assuming all other variables remain constant.\n",
    "\n",
    "- **bathrooms:** With a coefficient of 2.569e+04, the presence of an additional bathroom is linked to a $25690 increase in price, assuming all other variables remain constant.\n",
    "\n",
    "- **yr_built**: The coefficient of -3188.3244 indicates that a one-year increment in the year built is associated with a $3188 reduction in price, holding all other variables constant.\n",
    "\n",
    "- **grade**: A one-unit increase in grade corresponds to a $120,300 price increase, as suggested by the coefficient of 1.203e+05, assuming other variables remain constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating mean absolute error\n",
    "mae = results.resid.abs().sum() / len(y)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above MAE value means that for every house sale price prediction, our model is off by about 113,689. \n",
    "While this is quite a high number, it could be explained by the fact that our model predicts only about 58% of the variance in our dependent variable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings and Summary\n",
    "\n",
    "The predictor variables that are best correlated with the house sale price include grade, sqft_living, sqft_living15, sqft_above, bathrooms, view and bedrooms. \n",
    "Due to multicollinearity issues however, we can only include sqft_living and not sqft_living15 and sqft_above in a regression model. \n",
    "\n",
    "The variables that best predict the house sale price in a multiple linear regression model include sqft_living, sqft_lot, bedrooms, bathrooms, yr_built and grade.\n",
    "\n",
    "These 6 variables give the best R-squared value of all the models that we fitted and together they explain for about 58% of the model variance. \n",
    "\n",
    "Based on our model analysis, it is evident that grade, bedrooms and bathrooms have the highest influence on the house price. \n",
    "High grade rating and increased number of bathrooms greatly increase house prices. \n",
    "Many bedrooms on the other hand decrease house prices, perhaps because the demand for luxurious housing associated with many bedrooms is not high in King County. \n",
    "\n",
    "Year built, square foot living and square foot of the lot on which a house is built on have significant influence on the house price as well.\n",
    "\n",
    "The house features that developers can focus on to enhance affordable housing include bedrooms, bathrooms, grading and a waterfront. \n",
    "\n",
    "The typical expensive house will have an average number of bedrooms, higher than average number of bathrooms, a high grading and  a waterfront. \n",
    "\n",
    "Affordable housing therefore needs to focus on an average number of bedrooms, bathrooms, average grading and no waterfront. \n",
    "\n",
    "However, it is crucial to acknowledge certain limitations in the model. In order to align with our assumptions, we implemented log-transformations on select variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "In our quest to provide affordable housing solutions in King County, we recommned focusing on features that will ensure a standard and comfortable living space without including luxurious features that will push the price higher up. \n",
    "\n",
    "On this note we recommend developers to:\n",
    "\n",
    "- Prioritize the construction of houses with a an average grade rating. These will be comfortable without experiencing the price inflation associated with higher grade rating.\n",
    "\n",
    "- Focus more on properties away from the waterfront where price tends to be very high. \n",
    "\n",
    "- Limit the number of bedrooms and bathrooms to the requirements of an average home buyer in King County. Many bathrooms will increase house prices while many bedrooms will decrease prices as many people do not seem to be searching for luxurious housing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Analysis\n",
    "\n",
    "Investigate the impact of year renovated in relation to year built\n",
    "\n",
    "Investigate the cause of the price decrease with increase in the number of bedrooms\n",
    "\n",
    "Expand the dataset size to enhance model robustness.\n",
    "\n",
    "Validate model predictions against a separate test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
